{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WAPOLAB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6xoyiGaHBGb/OBlfBXXSQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jppyykm/Playground/blob/master/NLP_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiJ2iofQ94jC"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdQgPvvz549J"
      },
      "source": [
        "import requests, sqlite3, re, csv\n",
        "import datetime, time\n",
        "from datetime import date\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypKH9I7H6DYs",
        "outputId": "5128dc4c-be91-4713-be27-7eeb0f4fa52d"
      },
      "source": [
        "import nltk\n",
        "\n",
        "#from nltk import WordNetLemmatizer\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8BJ5dvG90mC"
      },
      "source": [
        "#Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BA0UiHB9oZ0"
      },
      "source": [
        "def rd(number): #Round to two decimal places\r\n",
        "  rnd = round(number,2)\r\n",
        "  return rnd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxmJZm_QMdbn"
      },
      "source": [
        "def klean(List): #Remove non-alphabetic tokens, such as punctuation ##BETA## \n",
        "  words = [word.lower() for word in List if word.isalpha()]\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFLBqAQN63FT"
      },
      "source": [
        "#Scraper Washington Post"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "nRvLoorn69zx",
        "outputId": "7e0ee9f1-e7d7-4b49-9f4a-3d838c71c645"
      },
      "source": [
        "'''\n",
        "#a = 'https://www.washingtonpost.com/health/covid-vaccine-health-care-ambassadors/2020/12/18/0c08298e-3ef9-11eb-9453-fc36ba051781_story.html'\n",
        "#a='https://www.washingtonpost.com/dc-md-va/2020/12/04/2021-inauguration-biden-harris/'\n",
        "a ='https://www.washingtonpost.com/politics/kamala-harris-sworn-in/2021/01/20/a184a12e-5aa9-11eb-b8bd-ee36b1cd18bf_story.html'\n",
        "soup = BeautifulSoup(requests.get(a).content, 'html.parser')\n",
        "rawtext = str(soup.findAll(\"p\"))\n",
        "text = re.sub(r'<.+?>', '', str(rawtext)) #Removes tags between < >\n",
        "\n",
        "lest = text.split(\"Coronavirus maps\")\n",
        "text = lest[0]\n",
        "text = text.replace(u'\\xa0', u' ')\n",
        "text = re.sub(r'\\.\\,','.',text)\n",
        "text[0:750]'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#a = \\'https://www.washingtonpost.com/health/covid-vaccine-health-care-ambassadors/2020/12/18/0c08298e-3ef9-11eb-9453-fc36ba051781_story.html\\'\\n#a=\\'https://www.washingtonpost.com/dc-md-va/2020/12/04/2021-inauguration-biden-harris/\\'\\na =\\'https://www.washingtonpost.com/politics/kamala-harris-sworn-in/2021/01/20/a184a12e-5aa9-11eb-b8bd-ee36b1cd18bf_story.html\\'\\nsoup = BeautifulSoup(requests.get(a).content, \\'html.parser\\')\\nrawtext = str(soup.findAll(\"p\"))\\ntext = re.sub(r\\'<.+?>\\', \\'\\', str(rawtext)) #Removes tags between < >\\n\\nlest = text.split(\"Coronavirus maps\")\\ntext = lest[0]\\ntext = text.replace(u\\'\\xa0\\', u\\' \\')\\ntext = re.sub(r\\'\\\\.\\\\,\\',\\'.\\',text)\\ntext[0:750]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znkZ2GlIH2ip"
      },
      "source": [
        "def scrape(url): #For Washington Post links\r\n",
        "  soup = BeautifulSoup(requests.get(url).content, 'html.parser')\r\n",
        "  rawtext = str(soup.findAll(\"p\"))\r\n",
        "  text = re.sub(r'<.+?>', '', str(rawtext)) #Removes tags between < >\r\n",
        "\r\n",
        "  lest = text.split(\"Coronavirus maps\")\r\n",
        "  text = lest[0]\r\n",
        "  text = text.replace(u'\\xa0', u' ')\r\n",
        "  text = re.sub(r'\\.\\,','.',text)\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2z_iHqHILBS",
        "outputId": "58c35985-fdf0-47e5-c37b-e3f905b1a5b7"
      },
      "source": [
        "%%time\n",
        "#INPUT URL\n",
        "#text = scrape(input())\n",
        "text = scrape('https://www.washingtonpost.com/politics/kamala-harris-sworn-in/2021/01/20/a184a12e-5aa9-11eb-b8bd-ee36b1cd18bf_story.html')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.16 s, sys: 19.6 ms, total: 1.18 s\n",
            "Wall time: 11.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7MZQ7W9G00"
      },
      "source": [
        "#Word and Sentence Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apeKSxMMPW9T"
      },
      "source": [
        "def tokenize(text):\n",
        "  without_puctuation = re.sub(r'[^\\w\\s]', '', text)\n",
        "  text_tok = word_tokenize(without_puctuation)\n",
        "  sent_tok = sent_tokenize(text)\n",
        "  ret = [text_tok,sent_tok]\n",
        "  return ret #Returns a list of two items: word tokens and sentence tokens."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UEZrhNhQET8",
        "outputId": "549311de-a93d-4f00-88be-eede89ef8180"
      },
      "source": [
        "tokenized = tokenize(text)\n",
        "\n",
        "print('Work tokens:',tokenized[0][0:50],'\\nNumber of tokens:',len(tokenized[0]),'\\n')\n",
        "print('Sentence tokens:',tokenized[1][0:4],'\\nNumber of sentences:',len(tokenized[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Work tokens: ['Kamala', 'D', 'Harris', 'was', 'sworn', 'in', 'as', 'vice', 'president', 'of', 'the', 'United', 'States', 'on', 'Wednesday', 'shattering', 'barriers', 'not', 'only', 'as', 'the', 'first', 'woman', 'to', 'hold', 'a', 'nationally', 'elected', 'office', 'but', 'also', 'the', 'first', 'Black', 'woman', 'and', 'first', 'Asian', 'American', 'to', 'reach', 'such', 'heights', 'As', 'the', 'world', 'watched', 'Harris', 'raised', 'her'] \n",
            "Number of tokens: 1703 \n",
            "\n",
            "Sentence tokens: ['[Kamala D. Harris was sworn in as vice president of the United States on Wednesday, shattering barriers not only as the first woman to hold a nationally elected office, but also the first Black woman and first Asian American to reach such heights.', 'As the world watched, Harris raised her right hand, face steeled as it was through so many hearings and debates that it became her signature stare.', 'Then, as Supreme Court Justice Sonia Sotomayor read “so help me God,” the stoicism broke.', '“So help me God,” Harris repeated, overcome with a smile as her sister, Maya, broke into tears behind her.'] \n",
            "Number of sentences: 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nDYNQ6iAjHN"
      },
      "source": [
        "#Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaNqwwWOW4NJ",
        "outputId": "15a1d723-e4fa-46fd-b9db-30312b29ab13"
      },
      "source": [
        "#Augments stopwords with capitalized instances\n",
        "def more_stop():\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  #This adds capitalized versions of the stopwords\n",
        "  more_stop = set()\n",
        "  for word in stop_words:\n",
        "    more_stop.add(word.capitalize())\n",
        "    more_stop.add(word)\n",
        "  return more_stop\n",
        "more_stop = more_stop()\n",
        "print(more_stop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Up', 'Itself', 'being', 'before', 'Both', \"needn't\", 'shouldn', 'Being', \"You've\", 'ma', 'having', 'if', 'Mightn', \"Mustn't\", 'Had', \"Should've\", 'against', 'Over', 'such', \"should've\", 'doesn', \"Wouldn't\", 'yours', 'Too', \"You'll\", 'Nor', 'should', 'while', 'Needn', 'but', 'nor', 'your', 'the', 'you', 'No', 'hers', 'under', 'our', \"Haven't\", 'Hasn', 'Our', 'Until', \"Mightn't\", 'My', 'those', 'be', \"mightn't\", 'Into', 'I', 'didn', 'for', 'Does', 'In', 'here', 'where', 'So', 'He', 'Her', 'Is', 'over', 'now', 'Don', 'Further', 'Of', 'Who', 'again', 'This', 'More', 'It', 'what', 'am', 'Are', 'Was', 'S', \"Hadn't\", 'Shouldn', 'below', \"hasn't\", 'To', 'we', 'and', 'which', 'Be', 'Between', 'And', 'other', 'On', 'who', 'Weren', \"wouldn't\", 'few', 'Before', \"Hasn't\", 'Ma', 'Whom', 'into', 'whom', \"she's\", 'are', 'ours', 'all', 'Now', 'Off', 'They', 'While', \"Couldn't\", 'than', \"weren't\", 'at', 't', 'Y', 've', 'when', 'Ourselves', 'Shan', 'then', 'won', \"haven't\", 'D', 'Themselves', 'Through', 'His', 'to', 'Didn', 'yourselves', 'they', 'She', 'We', 'Can', 'only', 'after', 'off', 'Ve', \"won't\", 'Have', 'Few', 'each', \"Needn't\", 'yourself', \"Aren't\", 'these', 'why', 'hasn', 'T', 'this', \"mustn't\", 'my', 'does', \"don't\", 'some', \"You'd\", \"you'll\", 'Than', 'Re', 'Again', 'Do', 'how', 'There', 'more', 'The', 'Wasn', \"you've\", 'o', \"Doesn't\", 'M', 'Not', 'Which', \"doesn't\", 'weren', 'Those', 'by', \"that'll\", 'Himself', \"That'll\", 'above', 'From', 'can', 'Mustn', 'did', 'Out', 'me', 'from', \"couldn't\", 'too', 'so', 'haven', 'ourselves', 'wouldn', 'During', 'him', 'a', 'Ain', 'Yourself', 'Doing', \"wasn't\", 'Each', 'on', 'Were', 'But', \"shan't\", 'ain', 're', 'How', 'What', 'needn', 'very', 'Doesn', 'myself', 'Has', 'Theirs', 'At', \"Don't\", 'mustn', 'Some', 'was', 'Most', 'herself', \"Won't\", \"Shouldn't\", 'not', 'aren', 'Them', 'doing', \"Shan't\", 'Hers', 'Me', 'through', 'itself', \"isn't\", 'Ll', 'Hadn', 'there', 'is', 'Or', 'Myself', 'an', \"didn't\", 'Will', 'don', \"She's\", 'Then', 'have', 'no', \"hadn't\", 'were', 'of', 'Yours', 'Other', 'All', 'further', 'Very', 'them', \"Wasn't\", 'Haven', 'Aren', 'will', \"Isn't\", 'just', \"shouldn't\", 'he', 'has', 'Their', 'in', 'own', 's', 'hadn', 'its', 'After', 'If', 'with', 'Am', 'Wouldn', 'theirs', 'because', 'Isn', 'By', 'Against', 'Below', 'Did', 'When', 'As', 'i', 'Down', 'Own', 'Only', 'You', 'as', 'Won', 'that', 'wasn', 'most', 'isn', 'Because', 'These', 'his', \"you're\", 'Its', 'themselves', 'Having', 'Same', 'Should', 'Couldn', 'O', \"Didn't\", 'Above', 'For', 'both', 'Why', 'mightn', 'her', 'once', \"It's\", \"Weren't\", 'A', 'up', 'd', 'Been', 'll', 'himself', \"You're\", 'Your', 'do', 'until', 'About', 'been', \"aren't\", 'she', 'down', 'couldn', 'between', 'Here', 'or', 'Herself', \"it's\", 'had', 'That', 'Ours', 'Yourselves', 'Where', 'Once', 'same', 'Such', 'their', 'about', \"you'd\", 'Just', 'it', 'during', 'shan', 'any', 'Him', 'y', 'An', 'Any', 'm', 'out', 'Under', 'With'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3-VTwa95A7"
      },
      "source": [
        "# OUTPUT = [FILTERED LIST, NUMBER OF STOPWORDS, NUMBER OF NON STOPWORDS]\n",
        "\n",
        "def remove_stop(inlist):\n",
        "  new_list = []\n",
        "  stop, nonstop = 0, 0\n",
        "  stop_words, more_stop = set(stopwords.words('english')), set()\n",
        "  \n",
        "  for word in stop_words: #Add capitalized Stopwords\n",
        "    more_stop.add(word.capitalize())\n",
        "    more_stop.add(word)\n",
        "\n",
        "  for i in inlist: #Stop/nonstop counter and filter\n",
        "    if i not in more_stop:\n",
        "      nonstop += 1\n",
        "      new_list.append(i)\n",
        "    else:\n",
        "      stop += 1\n",
        "\n",
        "  return(new_list, stop/(nonstop+stop))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvUScauM4els"
      },
      "source": [
        "##This allows to add stopwords as a second list argument \n",
        "\n",
        "def augment_stop(inlist, extralist):\n",
        "  new_list = []\n",
        "  stop, nonstop = 0, 0\n",
        "  stop_words, more_stop = set(stopwords.words('english')), set()\n",
        "  extralist = set(extralist)\n",
        "  \n",
        "  for word in stop_words: #Add capitalized Stopwords\n",
        "    more_stop.add(word.capitalize())\n",
        "    more_stop.add(word)\n",
        "\n",
        "  for i in inlist: #Stop/nonstop counter and filter\n",
        "    if i not in more_stop.union(extralist):\n",
        "      nonstop += 1\n",
        "      new_list.append(i)\n",
        "    else:\n",
        "      stop += 1\n",
        "\n",
        "  #return(new_list, stop/(nonstop+stop))\n",
        "  return(new_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "qkeIksbh7Mv9",
        "outputId": "9bae35df-9955-47c4-eb15-f0127090fcc4"
      },
      "source": [
        "txt = tokenize(text)\n",
        "type(txt)\n",
        "#augment_stop(txt, ['said'])\n",
        "extra_list = set(['said'])\n",
        "augment_stop(txt,extra_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-54d0d48b83dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#augment_stop(txt, ['said'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mextra_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'said'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maugment_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextra_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-a6f3c8a56150>\u001b[0m in \u001b[0;36maugment_stop\u001b[0;34m(inlist, extralist)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Stop/nonstop counter and filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmore_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextralist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mnonstop\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mnew_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzppQrAx7Mx5"
      },
      "source": [
        "augment_stop(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMEyK95PDoVn"
      },
      "source": [
        "no_stopwords = remove_stop(tokenized[0])[0]\n",
        "ratio = rd(len(no_stopwords)/len(tokenized[0])*100)\n",
        "print('Number of total tokens:',len(tokenized[0]))\n",
        "print('Number of tokens without stopwords:',len(no_stopwords))\n",
        "print('It decreased',str(100-ratio)+'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OlJ3BUO-Y4P"
      },
      "source": [
        "remove_stop(tokenized[0])[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnv31xwa_Wcg"
      },
      "source": [
        "#Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96gJYbwM_Z5M"
      },
      "source": [
        "unique = set(no_stopwords)\n",
        "print('Number of unique words in dictionary:',len(unique))\n",
        "print('Ratio of filtered tokens to unique words: ',str(round(len(unique)/len(no_stopwords)*100,2))+'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3FDGtZ3O3pe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6t2PbRaVG3F"
      },
      "source": [
        "#Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsXpuQLSVJnn"
      },
      "source": [
        "frequency_distribution = FreqDist(no_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iazgZSSIVWG-"
      },
      "source": [
        "print(frequency_distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX4zpOkGVkI0"
      },
      "source": [
        "frequency_distribution.plot(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qftU7hwsVt-u"
      },
      "source": [
        "new = scrape('https://www.washingtonpost.com/technology/2021/01/20/qanon-trump-era-ends/')\r\n",
        "new_tokens = tokenize(new)[0]\r\n",
        "new_stop = remove_stop(new_tokens)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAe2j46bKNAi"
      },
      "source": [
        "new_frequency = FreqDist(new_stop)\r\n",
        "new_frequency.plot(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC1xp4NaKxx6"
      },
      "source": [
        "%%time\r\n",
        "combo('https://www.washingtonpost.com/history/2021/01/20/presidential-notes-inauguration-trump-biden/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLuRRwvNcM_C"
      },
      "source": [
        "#Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrZ04oEucLvp"
      },
      "source": [
        "def porter(List):\r\n",
        "  ps = PorterStemmer()\r\n",
        "  ret = []\r\n",
        "  for word in List:\r\n",
        "    ret.append(ps.stem(word))\r\n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBQlzRw6cqBH"
      },
      "source": [
        "PStest = remove_stop(tokenized[0])\r\n",
        "PStest = porter(PStest[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2aHNZSugRkp"
      },
      "source": [
        "for i in range(20,40):\r\n",
        "  print(no_stopwords[i],'::',PStest[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjTWtKOLggqZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ELDCgIhrjr"
      },
      "source": [
        "#Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Vofqnshs0P"
      },
      "source": [
        "def lemma(List):\r\n",
        "  ret = []\r\n",
        "  lemmatizer = WordNetLemmatizer()\r\n",
        "  for word in List:\r\n",
        "    ret.append(lemmatizer.lemmatize(word))\r\n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTihxTtzUTSl"
      },
      "source": [
        "lem = WordNetLemmatizer()\n",
        "lem.lemmatize('congratulate')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQYqDbviLLD"
      },
      "source": [
        "LemTest = remove_stop(tokenized[0])\r\n",
        "LemTest = lemma(LemTest[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjFctMJWigH6"
      },
      "source": [
        "for i in range(70,90):\r\n",
        "  print(no_stopwords[i],'::',LemTest[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rce8y6mCiufR"
      },
      "source": [
        "sentences = sent_tokenize(text) # NLTK function\r\n",
        "total_documents = len(sentences)\r\n",
        "\r\n",
        "def create_frequency_matrix(sentences):\r\n",
        "    frequency_matrix = {}\r\n",
        "    stopWords = set(stopwords.words(\"english\"))\r\n",
        "    ps = PorterStemmer()\r\n",
        "\r\n",
        "    for sent in sentences:\r\n",
        "        freq_table = {}\r\n",
        "        words = word_tokenize(sent)\r\n",
        "        for word in words:\r\n",
        "            word = word.lower()\r\n",
        "            word = ps.stem(word)\r\n",
        "            if word in stopWords:\r\n",
        "                continue\r\n",
        "\r\n",
        "            if word in freq_table:\r\n",
        "                freq_table[word] += 1\r\n",
        "            else:\r\n",
        "                freq_table[word] = 1\r\n",
        "\r\n",
        "        frequency_matrix[sent[:15]] = freq_table\r\n",
        "\r\n",
        "    return frequency_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVhi2Kopjm3y"
      },
      "source": [
        "create_frequency_matrix(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKtFLsXmjrrj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elmi2fUb_mFI"
      },
      "source": [
        "#Synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6p7oNsM_qDD"
      },
      "source": [
        "x = 203\n",
        "syns = wordnet.synsets(LemTest[x])\n",
        "print(LemTest[x])\n",
        "print(syns[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMM_bUCX_25-"
      },
      "source": [
        "LemTest[x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmgtWVhIAFVQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J86rRRbOKa0"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v25EucQSOMpJ"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "info = api.info()\n",
        "print(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guhPb4uNOe5f"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOFLo_QYO5oT"
      },
      "source": [
        "corpus = api.load(text)\n",
        "model = Word2Vec(corpus)\n",
        "#model.most_similar(\"car\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdx2hk1J55Cg"
      },
      "source": [
        "#Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL4lwINV3QhQ"
      },
      "source": [
        "def combo(url):\n",
        "  new = scrape(url)\n",
        "  new_tokens = tokenize(new)[0]\n",
        "  print('Word count:',len(new_tokens))\n",
        "  new_stop = remove_stop(new_tokens)[0]\n",
        "  print('Without stopwords:',len(new_stop))\n",
        "  new_frequency = FreqDist(new_stop)\n",
        "  new_frequency.plot(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLpLQ-J0PC_T"
      },
      "source": [
        "%%time\n",
        "combo('https://www.washingtonpost.com/national-security/fbi-agents-killed-florida/2021/02/05/f40f90f6-672f-11eb-8468-21bc48f07fe5_story.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFlwtgm33k7u"
      },
      "source": [
        "swordlist = []\n",
        "[swordlist.append(i) for i in stopwords.words('english')]\n",
        "'said' in swordlist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZSlzRIg6gjV"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_-bZZ0m33Qz"
      },
      "source": [
        "txt = tokenize(text)\n",
        "augment_stop(txt, ['said'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbQ4if8m6Eox"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}